#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•WordæŠ¥å‘Šç”Ÿæˆ
"""
import sys
import os
import json
import traceback
from pathlib import Path

# æ·»åŠ backendåˆ°path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

def debug_word_generation():
    """è°ƒè¯•WordæŠ¥å‘Šç”Ÿæˆ"""
    task_id = "9ea02dd3-9e29-4309-ab3e-1c2172909982"
    
    print(f"ğŸ”§ è°ƒè¯•WordæŠ¥å‘Šç”Ÿæˆï¼Œtask_id: {task_id}")
    print("=" * 60)
    
    # 1. æ£€æŸ¥åˆ†æç»“æœæ–‡ä»¶
    print("1. æ£€æŸ¥åˆ†æç»“æœæ–‡ä»¶...")
    charts_dir = Path("backend/static/charts") / task_id
    analysis_file = charts_dir / "analysis_results.json"
    
    if analysis_file.exists():
        print(f"âœ… åˆ†æç»“æœæ–‡ä»¶å­˜åœ¨: {analysis_file}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {analysis_file.stat().st_size:,} å­—èŠ‚")
        
        # è¯»å–å’ŒéªŒè¯JSON
        try:
            with open(analysis_file, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            print(f"âœ… JSONæ–‡ä»¶æ ¼å¼æ­£ç¡®")
            print(f"ğŸ“‹ åŒ…å«çš„é”®: {list(analysis_data.keys())}")
            
            # æ£€æŸ¥æ•°æ®ç»“æ„
            print("\nğŸ“Š æ•°æ®ç»“æ„åˆ†æ:")
            for key, value in analysis_data.items():
                if isinstance(value, list):
                    print(f"  {key}: åˆ—è¡¨, é•¿åº¦={len(value)}")
                    if len(value) > 0:
                        print(f"    ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹: {type(value[0])}")
                elif isinstance(value, dict):
                    print(f"  {key}: å­—å…¸, é”®æ•°é‡={len(value)}")
                else:
                    print(f"  {key}: {type(value)}")
        except Exception as e:
            print(f"âŒ JSONæ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return False
    else:
        print(f"âŒ åˆ†æç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {analysis_file}")
        return False
    
    # 2. æ£€æŸ¥å›¾è¡¨æ–‡ä»¶
    print("\n2. æ£€æŸ¥å›¾è¡¨æ–‡ä»¶...")
    if charts_dir.exists():
        chart_files = list(charts_dir.glob("*.png"))
        print(f"âœ… å›¾è¡¨ç›®å½•å­˜åœ¨: {charts_dir}")
        print(f"ğŸ“Š æ‰¾åˆ° {len(chart_files)} ä¸ªå›¾è¡¨æ–‡ä»¶")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå›¾è¡¨æ–‡ä»¶
        for i, chart in enumerate(chart_files[:5]):
            file_size = chart.stat().st_size
            print(f"  ğŸ–¼ï¸ {chart.name} ({file_size:,} å­—èŠ‚)")
    else:
        print(f"âŒ å›¾è¡¨ç›®å½•ä¸å­˜åœ¨: {charts_dir}")
        return False
    
    # 3. ç›´æ¥æµ‹è¯•WordæŠ¥å‘Šç”Ÿæˆ
    print("\n3. ç›´æ¥æµ‹è¯•WordæŠ¥å‘Šç”Ÿæˆ...")
    try:
        from backend.services.r_analysis import RAnalysisEngine
        
        engine = RAnalysisEngine()
        
        # ç”Ÿæˆä¸€ä¸ªç®€åŒ–çš„DeepSeekæŠ¥å‘Šç”¨äºæµ‹è¯•
        mock_deepseek_report = """
# å‹åŠ›é‡‡é›†æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
æœ¬æ¬¡åˆ†æå¯¹æœºå™¨äººå‹åŠ›é‡‡é›†ç³»ç»Ÿè¿›è¡Œäº†å…¨é¢çš„è´¨é‡è¯„ä¼°ã€‚

## ä¸»è¦å‘ç°
1. ç³»ç»Ÿæ•´ä½“è¡¨ç°è‰¯å¥½
2. å„ç›®æ ‡åŠ›å€¼çš„ç²¾åº¦ç¬¦åˆè¦æ±‚
3. å»ºè®®ç»§ç»­ç›‘æ§è¿‡ç¨‹ç¨³å®šæ€§

## å»ºè®®
- ç»´æŒå½“å‰æ ¡å‡†å‚æ•°
- å®šæœŸè¿›è¡Œç³»ç»Ÿç»´æŠ¤
        """
        
        print("ğŸ“ å¼€å§‹ç”Ÿæˆç»¼åˆWordæŠ¥å‘Š...")
        
        try:
            report_path = engine.generate_comprehensive_word_report(
                task_id=task_id,
                analysis_data=analysis_data,
                deepseek_report=mock_deepseek_report
            )
        except Exception as e:
            print(f"âŒ WordæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
            print("\nğŸ” è¯¦ç»†é”™è¯¯è¿½è¸ª:")
            tb = traceback.format_exc()
            print(tb)
            
            # å°è¯•æ‰¾åˆ°å…·ä½“çš„é”™è¯¯è¡Œ
            lines = tb.split('\n')
            for i, line in enumerate(lines):
                if "'list' object has no attribute 'items'" in line:
                    print(f"\nğŸ¯ é”™è¯¯ä½ç½®: {line}")
                    if i > 0:
                        print(f"ä¸Šä¸€è¡Œ: {lines[i-1]}")
                    if i < len(lines) - 1:
                        print(f"ä¸‹ä¸€è¡Œ: {lines[i+1]}")
                elif "File" in line and "line" in line:
                    print(f"ğŸ“ {line}")
            
            return False
        
        if report_path and Path(report_path).exists():
            file_size = Path(report_path).stat().st_size
            print(f"âœ… WordæŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {report_path}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
            
            # æ£€æŸ¥Wordæ–‡ä»¶å†…å®¹
            print("\n4. æ£€æŸ¥Wordæ–‡ä»¶å†…å®¹...")
            try:
                from docx import Document
                doc = Document(report_path)
                
                print(f"ğŸ“‹ æ®µè½æ•°é‡: {len(doc.paragraphs)}")
                print(f"ğŸ“Š è¡¨æ ¼æ•°é‡: {len(doc.tables)}")
                
                # æ£€æŸ¥å›¾ç‰‡
                inline_shapes = []
                for paragraph in doc.paragraphs:
                    for run in paragraph.runs:
                        if run._element.xpath('.//pic:pic'):
                            inline_shapes.extend(run._element.xpath('.//pic:pic'))
                
                print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(inline_shapes)}")
                
                if len(inline_shapes) > 0:
                    print("âœ… Wordæ–‡æ¡£åŒ…å«å›¾ç‰‡!")
                else:
                    print("âš ï¸ Wordæ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
                
                # æ˜¾ç¤ºéƒ¨åˆ†æ®µè½å†…å®¹
                print("\nğŸ“– å‰å‡ ä¸ªæ®µè½å†…å®¹:")
                for i, para in enumerate(doc.paragraphs[:5]):
                    if para.text.strip():
                        print(f"  {i+1}. {para.text[:100]}{'...' if len(para.text) > 100 else ''}")
                
                return True
                
            except Exception as e:
                print(f"âŒ æ£€æŸ¥Wordæ–‡ä»¶å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return False
        else:
            print("âŒ WordæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ WordæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = debug_word_generation()
    
    if success:
        print("\nğŸ‰ WordæŠ¥å‘Šç”Ÿæˆè°ƒè¯•æˆåŠŸ!")
    else:
        print("\nâŒ WordæŠ¥å‘Šç”Ÿæˆè°ƒè¯•å¤±è´¥")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("â€¢ æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶è·¯å¾„")
        print("â€¢ éªŒè¯å›¾è¡¨æ–‡ä»¶å®Œæ•´æ€§")
        print("â€¢ æ£€æŸ¥docxåº“æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("â€¢ æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—") 