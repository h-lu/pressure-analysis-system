#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤åçš„DeepSeekå‰ç«¯äº¤äº’åŠŸèƒ½
"""

import requests
import json
import time
from pathlib import Path

BASE_URL = "http://localhost:8000"

def test_complete_deepseek_workflow():
    """æµ‹è¯•å®Œæ•´çš„DeepSeekåˆ†æå·¥ä½œæµ"""
    print("ğŸš€ æµ‹è¯•å®Œæ•´çš„DeepSeekåˆ†æå·¥ä½œæµ")
    print("="*60)
    
    # 1. ä¸Šä¼ æ–‡ä»¶
    print("1. ä¸Šä¼ æ•°æ®æ–‡ä»¶...")
    test_file = Path("demo_data.csv")
    if not test_file.exists():
        print("âŒ æµ‹è¯•æ–‡ä»¶ demo_data.csv ä¸å­˜åœ¨")
        return False
    
    with open(test_file, 'rb') as f:
        files = {'file': f}
        response = requests.post(f"{BASE_URL}/api/upload", files=files)
    
    if response.status_code != 200:
        print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {response.status_code}")
        return False
    
    upload_data = response.json()
    file_id = upload_data['file_id']
    print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œfile_id: {file_id}")
    
    # 2. å¼€å§‹Råˆ†æ
    print("\n2. å¼€å§‹Råˆ†æ...")
    analysis_request = {
        "file_id": file_id,
        "target_forces": [5, 25, 50],
        "tolerance_abs": 2.0,
        "tolerance_pct": 5.0
    }
    
    response = requests.post(f"{BASE_URL}/api/analyze", json=analysis_request)
    if response.status_code != 200:
        print(f"âŒ åˆ†æå¯åŠ¨å¤±è´¥: {response.status_code}")
        return False
    
    task_data = response.json()
    task_id = task_data['task_id']
    print(f"âœ… åˆ†æä»»åŠ¡åˆ›å»ºæˆåŠŸï¼Œtask_id: {task_id}")
    
    # 3. ç­‰å¾…Råˆ†æå®Œæˆ
    print("\n3. ç­‰å¾…Råˆ†æå®Œæˆ...")
    max_wait = 120  # æœ€å¤šç­‰å¾…2åˆ†é’Ÿ
    start_time = time.time()
    
    while time.time() - start_time < max_wait:
        response = requests.get(f"{BASE_URL}/api/task/{task_id}")
        if response.status_code == 200:
            status_data = response.json()
            if status_data['status'] == 'completed':
                print("âœ… Råˆ†æå®Œæˆ")
                break
            elif status_data['status'] == 'failed':
                print(f"âŒ Råˆ†æå¤±è´¥: {status_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        
        print(".", end="", flush=True)
        time.sleep(2)
    else:
        print("âŒ Råˆ†æè¶…æ—¶")
        return False
    
    # 4. è·å–Råˆ†æç»“æœ
    print("\n4. è·å–Råˆ†æç»“æœ...")
    response = requests.get(f"{BASE_URL}/api/results/{task_id}")
    if response.status_code != 200:
        print(f"âŒ è·å–åˆ†æç»“æœå¤±è´¥: {response.status_code}")
        return False
    
    analysis_result = response.json()
    print("âœ… Råˆ†æç»“æœè·å–æˆåŠŸ")
    
    # 5. ç”ŸæˆDeepSeekåˆ†æ
    print("\n5. ç”ŸæˆDeepSeek AIåˆ†æ...")
    deepseek_request = {
        "analysis_data": {
            **analysis_result['result'],
            "task_id": task_id  # é‡è¦ï¼šåŒ…å«task_id
        },
        "report_type": "comprehensive",
        "language": "chinese"
    }
    
    response = requests.post(f"{BASE_URL}/api/deepseek/generate-report", json=deepseek_request)
    if response.status_code != 200:
        print(f"âŒ DeepSeekåˆ†æå¤±è´¥: {response.status_code}")
        print(f"é”™è¯¯è¯¦æƒ…: {response.text}")
        return False
    
    deepseek_result = response.json()
    print("âœ… DeepSeek AIåˆ†æå®Œæˆ")
    print(f"ğŸ“ æŠ¥å‘Šé•¿åº¦: {len(deepseek_result['report'])} å­—ç¬¦")
    
    # 6. æ£€æŸ¥åç«¯æ˜¯å¦ä¿å­˜äº†DeepSeekåˆ†æç»“æœ
    print("\n6. æ£€æŸ¥åç«¯ä¿å­˜çš„DeepSeekåˆ†æç»“æœ...")
    response = requests.get(f"{BASE_URL}/api/chart/{task_id}/deepseek_analysis.json")
    if response.status_code == 200:
        saved_result = response.json()
        print("âœ… åç«¯æˆåŠŸä¿å­˜äº†DeepSeekåˆ†æç»“æœ")
        print(f"ğŸ“ ä¿å­˜çš„æŠ¥å‘Šé•¿åº¦: {len(saved_result['report'])} å­—ç¬¦")
    else:
        print("âš ï¸  åç«¯æ²¡æœ‰ä¿å­˜DeepSeekåˆ†æç»“æœ")
    
    # 7. ç”Ÿæˆç»¼åˆWordæŠ¥å‘Š
    print("\n7. ç”Ÿæˆç»¼åˆWordæŠ¥å‘Š...")
    response = requests.post(f"{BASE_URL}/api/deepseek/generate-comprehensive-word-report?task_id={task_id}")
    if response.status_code != 200:
        print(f"âŒ WordæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {response.status_code}")
        print(f"é”™è¯¯è¯¦æƒ…: {response.text}")
        return False
    
    word_result = response.json()
    print("âœ… ç»¼åˆWordæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
    
    # 8. æµ‹è¯•ä¸‹è½½WordæŠ¥å‘Š
    print("\n8. æµ‹è¯•ä¸‹è½½WordæŠ¥å‘Š...")
    response = requests.get(f"{BASE_URL}/api/download-comprehensive-report/{task_id}")
    if response.status_code == 200:
        # ä¿å­˜ä¸‹è½½çš„æ–‡ä»¶
        download_file = Path(f"test_downloaded_report_{task_id}.docx")
        with open(download_file, 'wb') as f:
            f.write(response.content)
        
        print(f"âœ… WordæŠ¥å‘Šä¸‹è½½æˆåŠŸ: {download_file}")
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {download_file.stat().st_size} å­—èŠ‚")
        
        if download_file.stat().st_size > 1000:
            print("âœ… æ–‡ä»¶å¤§å°æ­£å¸¸")
        else:
            print("âš ï¸  æ–‡ä»¶å¤§å°å¯èƒ½å¼‚å¸¸")
    else:
        print(f"âŒ WordæŠ¥å‘Šä¸‹è½½å¤±è´¥: {response.status_code}")
        return False
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DeepSeekå‰ç«¯äº¤äº’åŠŸèƒ½ä¿®å¤æˆåŠŸï¼")
    print(f"ğŸ“‹ ä»»åŠ¡ID: {task_id}")
    print("ğŸ’¡ å‰ç«¯ç°åœ¨åº”è¯¥èƒ½å¤Ÿ:")
    print("   â€¢ æ­£ç¡®ç”Ÿæˆå’Œæ˜¾ç¤ºDeepSeekåˆ†ææŠ¥å‘Š")
    print("   â€¢ ä»åç«¯åŠ è½½å·²ä¿å­˜çš„åˆ†æç»“æœ")
    print("   â€¢ ç”Ÿæˆå’Œä¸‹è½½ç»¼åˆWordæŠ¥å‘Š")
    print("="*60)
    
    return True

if __name__ == "__main__":
    print("ğŸ”§ DeepSeekå‰ç«¯äº¤äº’åŠŸèƒ½æµ‹è¯•")
    print("è¯·ç¡®ä¿åç«¯æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ (uvicorn backend.main:app --reload)")
    
    input("\nğŸ“‹ æŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")
    
    success = test_complete_deepseek_workflow()
    
    if success:
        print("\nğŸŠ æµ‹è¯•å®Œæˆï¼ä¿®å¤åçš„åŠŸèƒ½å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("\nï¿½ï¿½ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯ã€‚") 