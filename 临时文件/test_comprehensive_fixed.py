#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤åçš„ç»¼åˆWordæŠ¥å‘Šç”Ÿæˆ
"""
import sys
import os
import json
from pathlib import Path

# æ·»åŠ backendåˆ°path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

def test_comprehensive_fixed():
    """æµ‹è¯•ä¿®å¤åçš„ç»¼åˆæŠ¥å‘Šç”Ÿæˆ"""
    task_id = "9ea02dd3-9e29-4309-ab3e-1c2172909982"
    
    print(f"ğŸ”§ æµ‹è¯•ä¿®å¤åçš„ç»¼åˆWordæŠ¥å‘Šç”Ÿæˆï¼Œtask_id: {task_id}")
    print("=" * 60)
    
    try:
        from backend.services.r_analysis import RAnalysisEngine
        
        # è¯»å–åˆ†ææ•°æ®
        charts_dir = Path("backend/static/charts") / task_id
        analysis_file = charts_dir / "analysis_results.json"
        
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        
        print("âœ… åˆ†ææ•°æ®è¯»å–æˆåŠŸ")
        
        # éªŒè¯æ•°æ®ç»“æ„
        print("ğŸ“Š éªŒè¯æ•°æ®ç»“æ„:")
        print(f"  data_summary: {type(analysis_data.get('data_summary'))}")
        print(f"  overall_stats: {type(analysis_data.get('overall_stats'))}")
        print(f"  target_analysis: {type(analysis_data.get('target_analysis'))}")
        
        engine = RAnalysisEngine()
        
        # ç”Ÿæˆä¸€ä¸ªç®€åŒ–çš„DeepSeekæŠ¥å‘Šç”¨äºæµ‹è¯•
        mock_deepseek_report = """
# å‹åŠ›é‡‡é›†æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
æœ¬æ¬¡åˆ†æå¯¹æœºå™¨äººå‹åŠ›é‡‡é›†ç³»ç»Ÿè¿›è¡Œäº†å…¨é¢çš„è´¨é‡è¯„ä¼°ã€‚

## ä¸»è¦å‘ç°
1. ç³»ç»Ÿæ•´ä½“è¡¨ç°è‰¯å¥½
2. å„ç›®æ ‡åŠ›å€¼çš„ç²¾åº¦ç¬¦åˆè¦æ±‚
3. å»ºè®®ç»§ç»­ç›‘æ§è¿‡ç¨‹ç¨³å®šæ€§

## å»ºè®®
- ç»´æŒå½“å‰æ ¡å‡†å‚æ•°
- å®šæœŸè¿›è¡Œç³»ç»Ÿç»´æŠ¤
        """
        
        print("ğŸ“ å¼€å§‹ç”Ÿæˆç»¼åˆWordæŠ¥å‘Š...")
        
        # ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼Œæ•è·è¯¦ç»†é”™è¯¯
        try:
            report_path = engine.generate_comprehensive_word_report(
                task_id=task_id,
                analysis_data=analysis_data,
                deepseek_report=mock_deepseek_report
            )
            
            if report_path and Path(report_path).exists():
                file_size = Path(report_path).stat().st_size
                print(f"âœ… WordæŠ¥å‘Šç”ŸæˆæˆåŠŸ!")
                print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„: {report_path}")
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
                
                # æ£€æŸ¥Wordæ–‡ä»¶å†…å®¹
                print("\nğŸ“– æ£€æŸ¥Wordæ–‡ä»¶å†…å®¹...")
                try:
                    from docx import Document
                    doc = Document(report_path)
                    
                    print(f"ğŸ“‹ æ®µè½æ•°é‡: {len(doc.paragraphs)}")
                    print(f"ğŸ“Š è¡¨æ ¼æ•°é‡: {len(doc.tables)}")
                    
                    # æ£€æŸ¥å›¾ç‰‡
                    inline_shapes = []
                    for paragraph in doc.paragraphs:
                        for run in paragraph.runs:
                            if run._element.xpath('.//pic:pic'):
                                inline_shapes.extend(run._element.xpath('.//pic:pic'))
                    
                    print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(inline_shapes)}")
                    
                    if len(inline_shapes) > 0:
                        print("âœ… Wordæ–‡æ¡£åŒ…å«å›¾ç‰‡!")
                    else:
                        print("âš ï¸ Wordæ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
                    
                    return True
                    
                except Exception as e:
                    print(f"âŒ æ£€æŸ¥Wordæ–‡ä»¶å¤±è´¥: {e}")
                    return False
            else:
                print("âŒ WordæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ WordæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
            
            # è¯¦ç»†é”™è¯¯è¿½è¸ª
            import traceback
            tb = traceback.format_exc()
            print("\nğŸ” è¯¦ç»†é”™è¯¯è¿½è¸ª:")
            print(tb)
            
            # æŸ¥æ‰¾å…·ä½“é”™è¯¯ä½ç½®
            lines = tb.split('\n')
            for i, line in enumerate(lines):
                if "'list' object has no attribute 'items'" in line:
                    print(f"\nğŸ¯ é”™è¯¯ä½ç½®: {line}")
                    # æŸ¥æ‰¾ç›¸å…³çš„æ–‡ä»¶å’Œè¡Œå·
                    for j in range(max(0, i-10), min(len(lines), i+3)):
                        if "File" in lines[j] and "line" in lines[j]:
                            print(f"ğŸ“ {lines[j]}")
                        elif lines[j].strip() and not lines[j].startswith("Traceback"):
                            print(f"   {lines[j]}")
            
            return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_comprehensive_fixed()
    
    if success:
        print("\nğŸ‰ ç»¼åˆWordæŠ¥å‘Šæµ‹è¯•æˆåŠŸ!")
    else:
        print("\nâŒ ç»¼åˆWordæŠ¥å‘Šæµ‹è¯•å¤±è´¥") 