#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆçš„å®Œæ•´ç»¼åˆæŠ¥å‘Šæµ‹è¯•
"""
import requests
import json
import time
from pathlib import Path

def final_comprehensive_test():
    """æœ€ç»ˆçš„å®Œæ•´ç»¼åˆæŠ¥å‘Šæµ‹è¯•"""
    print("ğŸ¯ æœ€ç»ˆçš„å®Œæ•´ç»¼åˆæŠ¥å‘Šæµ‹è¯•")
    print("=" * 60)
    
    # ä½¿ç”¨å·²æœ‰çš„task_id
    task_id = "9ea02dd3-9e29-4309-ab3e-1c2172909982"
    
    # 1. æµ‹è¯•APIç”Ÿæˆç»¼åˆæŠ¥å‘Š
    print("1. æµ‹è¯•APIç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
    try:
        response = requests.post(
            f'http://localhost:8000/api/deepseek/generate-comprehensive-word-report?task_id={task_id}',
            headers={'Content-Type': 'application/json'},
            timeout=60
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… APIè°ƒç”¨æˆåŠŸ")
            print(f"ğŸ“Š å“åº”: {result}")
            
            if result.get('success'):
                download_url = result.get('download_url')
                report_path = result.get('report_path')
                print(f"ğŸ“„ æŠ¥å‘Šè·¯å¾„: {report_path}")
                print(f"ğŸ”— ä¸‹è½½URL: {download_url}")
            else:
                print("âŒ APIè¿”å›å¤±è´¥çŠ¶æ€")
                return False
        else:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯å†…å®¹: {response.text}")
            return False
    except Exception as e:
        print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
        return False
    
    # 2. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
    print("\n2. éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶...")
    report_file = Path(f"temp/reports/comprehensive_analysis_report_{task_id}.docx")
    
    if report_file.exists():
        file_size = report_file.stat().st_size
        print(f"âœ… æŠ¥å‘Šæ–‡ä»¶å­˜åœ¨: {report_file}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
        
        if file_size > 500000:  # å¤§äº500KB
            print("âœ… æ–‡ä»¶å¤§å°æ­£å¸¸ï¼ŒåŒ…å«å®Œæ•´å†…å®¹")
        else:
            print("âš ï¸ æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´")
    else:
        print(f"âŒ æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {report_file}")
        return False
    
    # 3. æµ‹è¯•ä¸‹è½½åŠŸèƒ½
    print("\n3. æµ‹è¯•ä¸‹è½½åŠŸèƒ½...")
    try:
        download_response = requests.get(
            f'http://localhost:8000/api/download-comprehensive-report/{task_id}',
            timeout=30
        )
        
        if download_response.status_code == 200:
            print("âœ… ä¸‹è½½æˆåŠŸ")
            print(f"ğŸ“Š ä¸‹è½½æ–‡ä»¶å¤§å°: {len(download_response.content):,} å­—èŠ‚")
            
            # éªŒè¯Content-Type
            content_type = download_response.headers.get('content-type', '')
            if 'wordprocessingml' in content_type:
                print("âœ… æ–‡ä»¶ç±»å‹æ­£ç¡® (Wordæ–‡æ¡£)")
            else:
                print(f"âš ï¸ æ–‡ä»¶ç±»å‹å¼‚å¸¸: {content_type}")
            
            # éªŒè¯Content-Disposition
            content_disposition = download_response.headers.get('content-disposition', '')
            if 'attachment' in content_disposition:
                print("âœ… ä¸‹è½½å¤´è®¾ç½®æ­£ç¡®")
            else:
                print(f"âš ï¸ ä¸‹è½½å¤´å¼‚å¸¸: {content_disposition}")
                
        else:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {download_response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
        return False
    
    # 4. éªŒè¯Wordæ–‡æ¡£å†…å®¹
    print("\n4. éªŒè¯Wordæ–‡æ¡£å†…å®¹...")
    try:
        from docx import Document
        doc = Document(str(report_file))
        
        print(f"ğŸ“‹ æ®µè½æ•°é‡: {len(doc.paragraphs)}")
        print(f"ğŸ“Š è¡¨æ ¼æ•°é‡: {len(doc.tables)}")
        
        # æ£€æŸ¥å›¾ç‰‡
        inline_shapes = []
        for paragraph in doc.paragraphs:
            for run in paragraph.runs:
                if run._element.xpath('.//pic:pic'):
                    inline_shapes.extend(run._element.xpath('.//pic:pic'))
        
        print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(inline_shapes)}")
        
        # æ£€æŸ¥å…³é”®ç« èŠ‚
        key_sections = [
            "DeepSeek AIæ™ºèƒ½åˆ†ææŠ¥å‘Š",
            "Rç»Ÿè®¡åˆ†æè¯¦ç»†æ•°æ®ä¸å›¾è¡¨", 
            "ç»¼åˆç»“è®ºä¸å»ºè®®"
        ]
        
        found_sections = []
        for paragraph in doc.paragraphs:
            for section in key_sections:
                if section in paragraph.text:
                    found_sections.append(section)
        
        print(f"ğŸ“– æ‰¾åˆ°å…³é”®ç« èŠ‚: {len(set(found_sections))}/{len(key_sections)}")
        for section in set(found_sections):
            print(f"  âœ… {section}")
        
        # éªŒè¯å®Œæ•´æ€§
        if (len(doc.paragraphs) > 50 and 
            len(doc.tables) > 3 and 
            len(inline_shapes) > 0 and 
            len(set(found_sections)) >= 2):
            print("âœ… Wordæ–‡æ¡£å†…å®¹å®Œæ•´")
            return True
        else:
            print("âš ï¸ Wordæ–‡æ¡£å†…å®¹å¯èƒ½ä¸å®Œæ•´")
            return False
            
    except Exception as e:
        print(f"âŒ Wordæ–‡æ¡£éªŒè¯å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = final_comprehensive_test()
    
    if success:
        print("\nğŸ‰ æœ€ç»ˆç»¼åˆæŠ¥å‘Šæµ‹è¯•å®Œå…¨æˆåŠŸ!")
        print("\nâœ… æµ‹è¯•é€šè¿‡çš„åŠŸèƒ½:")
        print("  â€¢ APIç”Ÿæˆç»¼åˆæŠ¥å‘Š")
        print("  â€¢ æ–‡ä»¶æ­£ç¡®ä¿å­˜")
        print("  â€¢ ä¸‹è½½åŠŸèƒ½æ­£å¸¸")
        print("  â€¢ Wordæ–‡æ¡£å†…å®¹å®Œæ•´")
        print("  â€¢ åŒ…å«å›¾ç‰‡å’Œè¡¨æ ¼")
        print("  â€¢ åŒ…å«æ‰€æœ‰å…³é”®ç« èŠ‚")
    else:
        print("\nâŒ æœ€ç»ˆç»¼åˆæŠ¥å‘Šæµ‹è¯•å¤±è´¥") 